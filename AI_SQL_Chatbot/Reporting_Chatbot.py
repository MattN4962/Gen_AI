from bs4 import BeautifulSoup
import markdown
import mysql.connector
import pandas as pd
from transformers import pipeline
from dotenv import load_dotenv
import gradio as gr
import streamlit as st
import re
import os
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table
from reportlab.lib.styles import getSampleStyleSheet
from transformers import AutoTokenizer, AutoModelForCausalLM
from openai import AzureOpenAI
import pyodbc
#This file is just to test the connection and a simple query
# Database connection configuration

load_dotenv()
api_version = os.getenv("API_VERSION")
api_key = os.getenv("API_KEY")
azure_url = os.getenv("AZURE_URL")
sql_password = os.getenv("MY_SQL_PASSWORD")
azure_server = os.getenv("AZURE_SYNAPSE_SERVER")
azure_db = os.getenv("AZURE_SYNAPSE_DB")

config = {
    'user': 'root',
    'password': sql_password,
    'host': 'localhost',
    'port': 3306,
    'database':'Main'
}

conn_string = (
    "Driver={ODBC Driver 18 for SQL Server};"
    f"Server=tcp:{azure_server},1433;"
    f"Database={azure_db};"
    "Encrypt=yes;"
    "TrustServerCertificate=no;"
    "Connection Timeout=30;"
    "Authentication=ActiveDirectoryDefault;"
)

client = AzureOpenAI(
    api_version=api_version,
    azure_endpoint=azure_url,
    api_key=api_key
)

def get_db_connection():
    try:
        conn = pyodbc.connect(conn_string)
        cursor = conn.cursor(dictionary=True)
        print("Database connection established.")
        return conn, cursor
    except mysql.connector.Error as err:
        print(f"Error: {err}")
        return None, None

def get_schema():
    query = """
        SELECT
            TABLE_NAME   AS table_name,
            COLUMN_NAME  AS column_name,
            DATA_TYPE    AS data_type
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
        ORDER BY TABLE_NAME, ORDINAL_POSITION;
    """
    
    conn, cursor = get_db_connection()
    cursor.execute(query, ("Main",))
    rows = cursor.fetchall()

    df = pd.DataFrame(rows, columns=["table_name", "column_name", "data_type"])
    #print(df)
    schema_dict = (
            df.groupby("table_name")
              .apply(lambda g: [f"{col} ({dtype})" for col, dtype in zip(g.column_name, g.data_type)])
              .to_dict()
        )
    return schema_dict

def is_Sql_safe(query: str) -> bool:
    # Define a list of forbidden keywords
    forbidden_keywords = ['DROP', 'DELETE', 'INSERT', 'UPDATE', 'ALTER', 'CREATE', 'TRUNCATE', 'EXEC', 'EXECUTE']
    
    clean_sql = re.sub(r"```sql|```", "", query, flags=re.IGNORECASE).strip()

    # Check for forbidden keywords in the query (case-insensitive)
    if any(word in clean_sql for word in forbidden_keywords):
        return False
    if not clean_sql.startswith("SELECT"):
        return False
    return True

# Returns SQL query generated by the LLM
def generate_sql(user_query: str, schema: dict) -> str:
    response = client.chat.completions.create(
        messages=[
            {
                "role":"system",
                "content":f"""You will take the user query in natural language and produce a a SINGLE SQL query using only SELECT statements using MySQLServer syntax."
                " This is the table schema: {schema}, and the field is_Pro is either True or False """
            },
            {
                "role":"user",
                "content":user_query
            }
        ],
        temperature=0,
        max_tokens=200,
        model="chatgpt-4o-latest"
    )
    query = re.sub(r"```sql|```", "", response.choices[0].message.content, flags=re.IGNORECASE).strip() 
    return query

# Executes the SQL query and returns the results as a DataFrame
def run_SQL_query(sql: str) -> pd.DataFrame:
    conn, cursor = get_db_connection()
    if conn is None or cursor is None:
        return pd.DataFrame()
    
    if not is_Sql_safe(sql):
        print("Unsafe SQL query detected.")
        connection_cleanup(conn, cursor)
        return pd.DataFrame()
    
    try:
        cursor.execute(sql)
        results = cursor.fetchall()
        df = pd.DataFrame(results)
        return df
    except mysql.connector.Error as err:
        print(f"SQL Error: {err}")
        return pd.DataFrame()
    finally:
        connection_cleanup(conn, cursor)

# Close all connections
def connection_cleanup(conn, cursor):
    cursor.close()
    conn.close()
    print("Database connection closed.")

def generate_insights(df: pd.DataFrame, user_question: str):
    if df.empty:
        return "No query results so no insights report can be given"
    data_sample = df.head(30).to_markdown(index=False)

    prompt = (
        f"You are a marketing analyst. The user asked: '{user_question}'.\n"
        f"Here are the first rows of the query results:\n{data_sample}\n\n"
        "Provide a concise marketing analysis and suggestions based on these results. "
        "Focus on actionable strategies such as promotions, customer segmentation, "
        "or product opportunities. Write in clear natural language."
    )
    response = client.chat.completions.create(
        messages=[
            {"role": "system", "content": "You are an expert marketing analyst."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.6,
        max_tokens=1000,
        model="chatgpt-4o-latest"
    )

    return response.choices[0].message.content.strip()

def generate_report(df: pd.DataFrame, filename: str):
    doc = SimpleDocTemplate(filename)
    styles = getSampleStyleSheet()
    flow = [Paragraph("SQL Query Results Report", styles['Title']), Spacer(1, 12)]

    if not df.empty:
        data = [df.columns.tolist()] + df.values.tolist()
        flow.append(Paragraph("Table Data", styles["Heading2"]))
        flow.append(Table(data)) 
    else:
        flow.append(Paragraph("No Table Data Returned", styles["Normal"]))
    
    doc.build(flow)
get_db_connection()

# st.title("On-Demand SQL Reporting Bot")
# st.markdown("Type a natural language question to query your database")

# st.session_state.setdefault("last_df", None)
# st.session_state.setdefault("insighs", None)
# st.session_state.setdefault("reporting_bytes", None)

# user_query = st.text_area("Enter your question")

# if st.button("Run Query"):
#     schema = get_schema()
#     if not schema:
#         st.error("Unable to get schema")
#     else:
#         sql = generate_sql(user_query=user_query, schema=schema)
#         st.code(sql, language="sql")
        
#         df = run_SQL_query(sql=sql)
#         if not df.empty:
#             st.session_state["last_df"] = df
#             st.session_state["insights"] = None
#             st.session_state["report_bytes"] = None
#         else:
#             st.warning("No results found or unsafe query")

# if st.session_state['last_df'] is not None and not st.session_state['last_df'].empty:
#     st.subheader("Query Results")
#     st.dataframe(st.session_state["last_df"])

#     #Table download
#     csv_data = st.session_state["last_df"].to_csv(index=False, encoding="utf-8")
#     st.download_button(
#         "Download Table Data (CSV)",
#         csv_data,
#         file_name="query_results.csv",
#         mime="text/csv"
#     )
    
#     if st.button("Generate Marketing Report"):
#         # 1. Get natural language analysis
#         insights = generate_insights(st.session_state['last_df'], user_query)
#         st.session_state["insights"] = insights

#         # 2. Create PDF with insights + table
#         pdf_path = "marketing_report.pdf"
#         generate_report(st.session_state['last_df'], pdf_path)
#         with open(pdf_path, "rb") as f:
#             st.session_state["report_bytes"] = f.read()

#         # 3. Allow download
#         if st.session_state.get("insights"):
#             st.subheader("Marketing Insights")
#             st.markdown(st.session_state["insights"])

        


