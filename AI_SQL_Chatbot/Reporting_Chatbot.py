import mysql.connector
import pandas as pd
from transformers import pipeline
from dotenv import load_dotenv
import gradio as gr
import re
import os
from transformers import AutoTokenizer, AutoModelForCausalLM
from openai import AzureOpenAI
#This file is just to test the connection and a simple query
# Database connection configuration
config = {
    'user': 'root',
    'password': 'mysqlserver',
    'host': 'localhost',
    'port': 3306,
    'database':'Main'
}


# Load the language model

client = AzureOpenAI(
    api_version=api_version,
    azure_endpoint=azure_url
    
)


def get_db_connection():
    try:
        conn = mysql.connector.connect(**config)
        cursor = conn.cursor(dictionary=True)
        print("Database connection established.")
        return conn, cursor
    except mysql.connector.Error as err:
        print(f"Error: {err}")
        return None, None

def get_schema():
    query = """
        SELECT
            TABLE_NAME   AS table_name,
            COLUMN_NAME  AS column_name,
            DATA_TYPE    AS data_type
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s
        ORDER BY TABLE_NAME, ORDINAL_POSITION;
    """
    
    conn, cursor = get_db_connection()
    cursor.execute(query, ("Main",))
    rows = cursor.fetchall()

    df = pd.DataFrame(rows, columns=["table_name", "column_name", "data_type"])
    #print(df)
    schema_dict = (
            df.groupby("table_name")
              .apply(lambda g: [f"{col} ({dtype})" for col, dtype in zip(g.column_name, g.data_type)])
              .to_dict()
        )
    return schema_dict

def is_Sql_safe(query: str) -> bool:
    # Define a list of forbidden keywords
    forbidden_keywords = ['DROP', 'DELETE', 'INSERT', 'UPDATE', 'ALTER', 'CREATE', 'TRUNCATE', 'EXEC', 'EXECUTE']
    
    clean_sql = re.sub(r"```sql|```", "", query, flags=re.IGNORECASE).strip()

    # Check for forbidden keywords in the query (case-insensitive)
    if any(word in clean_sql for word in forbidden_keywords):
        return False
    if not clean_sql.startswith("SELECT"):
        return False
    return True

# Returns SQL query generated by the LLM
def generate_sql(user_query: str, schema: dict) -> str:
    response = client.chat.completions.create(
        messages=[
            {
                "role":"system",
                "content":f"""You will take the user query in natural language and produce a a SINGLE SQL query using only SELECT statements using MySQLServer syntax."
                " This is the table schema: {schema}"""
            },
            {
                "role":"user",
                "content":user_query
            }
        ],
        temperature=0,
        max_tokens=200,
        model="chatgpt-4o-latest"
    )
    return response

# Executes the SQL query and returns the results as a DataFrame
def run_SQL_query(sql: str) -> pd.DataFrame:
    conn, cursor = get_db_connection()
    if conn is None or cursor is None:
        return pd.DataFrame()
    
    if not is_Sql_safe(sql):
        print("Unsafe SQL query detected.")
        connection_cleanup(conn, cursor)
        return pd.DataFrame()
    
    try:
        cursor.execute(sql)
        results = cursor.fetchall()
        df = pd.DataFrame(results)
        return df
    except mysql.connector.Error as err:
        print(f"SQL Error: {err}")
        return pd.DataFrame()
    finally:
        connection_cleanup(conn, cursor)

# Close all connections
def connection_cleanup(conn, cursor):
    cursor.close()
    conn.close()
    print("Database connection closed.")


conn, cursor = get_db_connection()
schema = get_schema()
test_query = generate_sql("Show me the top selling products for the past 3 months", schema=schema)

query = re.sub(r"```sql|```", "", test_query.choices[0].message.content, flags=re.IGNORECASE).strip() 
result = run_SQL_query(query)
print(result)